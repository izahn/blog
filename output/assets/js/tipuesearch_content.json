{
  "pages": [
    {
      "title": "Useless but fun R packages",
      "text": "R is useful for many things. But, it is not only useful! There is plenty of fun to be had as well. In celebration of Summer I'm going to take a look at some useless (but fun!) R packages.\n\n\n\n\n\nFortune teller\n\n\nfortunes is probably the best-known \"just for fun\" R package. It is maintained by Achim Zeileis and features contributions from such R luminaries as Peter Dalgaard, Uwe Ligges, Kevin Wright, and many others. The fortunes package been amusing bored statisticians and programmers since 2004. Since that time the fortunes package developers have been selecting amusing quotes from the R-help mailing list and other sources and compiling them for your enjoyment. Let's take a look.\n\n\n## install.packages(\"fortunes\") # if you don't already have it\nlibrary(fortunes)\nfortune()\n\n\n\nWhen in doubt, keep adding slashes until it works.\n   -- Joran Elias (on how to escape a backslash in R)\n      Stackoverflow (March 2015)\n\n\n\nWhen called without arguments, the fortune function will select a random fortune. Calling fortune again will select another random quote:\n\nfortune()\n\n\n\nRAM is cheap and thinking hurts.\n   -- Uwe Ligges (about memory requirements in R)\n      R-help (June 2007)\n\n\n\nIf you want to specify a particular quote you can do so by number or by character search:\n\nfortune(204)\nfortune(\"memory\")\n\n\n\nmemory problems (not me. my pc!)\n   -- Sara Mouro (subject line for an R-help request)\n      R-help (January 2008)\n\nRAM is cheap and thinking hurts.\n   -- Uwe Ligges (about memory requirements in R)\n      R-help (June 2007)\n\n\n\nThat's about it. Well, there are some other options, see ?fortune for the details.\n\n\n\n\n\nCow says what?\n\n\nIf you are a Unix user of a certain age you have no doubt heard of the famous cowsay program. Now R users can join the fun with the cowsay R package by Scott Chamberlain. Like the fortunes package, cowsay exports just one function; say. Let's take a look:\n\n## install.packages(\"cowsay\")\nlibrary(cowsay)\nsay(\"Hello world!\")\n\n\n\n -------------- \nHello world! \n --------------\n    \\\n      \\\n        \\\n            |\\___/|\n          ==) Y (==\n            \\    /\n             )=*=(\n            /     \\\n            |     |\n           /| | | |\\\n           \\| | |_|/\\\n      jgs  //_// ___/\n               \\_)\n\n\n\nCute, but I was led to believe there would be a cow involved! \n\n\nsay(\"Moo may represent an idea, but only the cow knows.\\n --Mason Cooley\",\n    by = \"cow\")\n\n\n\n ----- \nMoo may represent an idea, but only the cow knows.\n --Mason Cooley \n ------ \n    \\   __ \n     \\  (oo)\\ ________ \n        (__)\\         )\\ /\\ \n             ||------w|\n             ||      ||\n\n\n\nThere is no option to randomly select an animal, but we can achieve that ourselves easily enough.\n\nsomeone_say_hello <- function() {\n  animal <- sample(names(animals), 1)\n  say(paste(\"Hello, I'm a \", animal, \".\", collapse = \"\"), by = animal)\n  }\nsomeone_say_hello()\n\n\n\n ----- \nHello, I'm a  bigcat . \n ------ \n    \\   \n     \\\n                \\`*-.\n                 )  _`-.\n                .  : `. .\n                : _   '  \\\n                ; *` _.   `*-._\n                `-.-'          `-.\n                  ;       `       `.\n                  :.       .       \\\n                  .\\  .   :   .-'   .\n                  '  `+.;  ;  '      :\n                  :  '  |    ;       ;-.\n                  ; '   : :`-:     _.`* ;\n               .*' /  .*' ; .*`- +'  `*'\n     [bug]     `*-*   `*-*  `*-*'\n\n\n\n\n\nPutting it all together\n\n\nWhen I teach R I emphasize composability. That is, unlike some other statistics packages, R enables you to take the output from one function and pass in on to another. We can take advantage of the excellent composability R provides to do useful things like extract coefficients from a list of model fits and put them into a LaTeX table. Or we can use it to do useless things like making a cow tell us our fortune.\n\n\nsomeone_say_my_fortune <- function(x) {\n  animal <- animal <- sample(names(animals), 1)\n  say(paste(fortune(), collapse = \"\\n\"), by = animal)\n}\nsomeone_say_my_fortune()\n\n\n\n ------------- \nOnly with a very high signal to noise ratio (e.g., high true R2) can \ntorturing data lead to a confession to something other than what the \nanalyst wants to hear.\nFrank Harrell\nNA\nR-help\nApril 2010 \n -------------- \n              \\   \n               \\  \n                \\\n_____________________                              _____________________\n`-._                 \\           |\\__/|           /                 _.-'\n    \\                 \\          |    |          /                 /\n     \\                 `-_______/      \\_______-'                 /\n      |                                                          |\n      |                                                          |\n      |                                                          |\n      /                                                          \\\n     /_____________                                  _____________\\\n                   `----._                    _.----'\n                          `--.            .--'\n                              `-.      .-'\n                                 \\    / :F_P:\n                                  \\  /\n                                   \\/\n\n\n\nBecause fortune gives a random quote each time, and we randomly select animals each time, we will get a surprising new delight every time we call the someone_say_my_fortune function.\n\nsomeone_say_my_fortune()\n\n\n\n ----- \nThere's an informal tradition that those announcements [about R releases]\ncontain at least one mistake, but apparently I forgot this time, so users \nhave to make up their own....\nPeter Dalgaard\nabout an apparent non-bug report in his former R-announce message\nR-help\nDecember 2009 \n ------ \n    \\   \n     \\\n         _\n       _/ }\n      `>' \\\n      `|   \\\n       |   /'-.     .-.\n        \\'     ';`--' .'\n         \\'.    `'-./\n          '.`-..-;`\n            `;-..'\n            _| _|\n            /` /` [nosig]\n\n\n\nIf you want to get really silly about it, you could call that function in your .Rprofile. Or, if you are package author you could add some spice to your warning and error messages by having an ASCII art animal say them. Go forth and have fun!\n\n\n\nIf you know of other useless (but fun!) R packages let me know in the comments.",
      "tags": "fun,R",
      "url": "http://people.fas.harvard.edu/~izahn/posts/useless-but-fun-r-packages/"
    },
    {
      "title": "Welcome",
      "text": "Hello, my name is Ista Zahn. Welcome to my blog!. I work as a Data Science Specialist at The Institute for Quantitative Social Science at Harvard University.\n\n\n\nI hold a master's degree in social psychology from the University of Rochester. During graduate school I discovered a love of statistical programming, primarily using the R environment for statistical computing. I am interested in using technology to turn raw data into information useful to human beings. My areas of expertise include data management, graphical displays, regression modeling, and web technologies for statistical computing and teaching.\n\n\n\nHere are some other places in addition to this blog that you can find me on the net.\n\n\n\n github My workshop materials, emacs config etc.\n\n stackoverflow My questions and answers (mostly R-related) on the popular question-and-answer site.\n\n Data Science Services at IQSS My awesome team at the Insitute for Quantitative Social Science at Harvard.",
      "tags": "",
      "url": "http://people.fas.harvard.edu/~izahn/pages/about/"
    },
    {
      "title": "Escaping from character encoding hell in R on Windows",
      "text": "Note: the title of this post was inspired by this question on stackoverflow.\n\n\n\nThis section gives the basic facts and recommendations for importing files with arbitrary encoding on Windows. The issues described here by and large to not apply on Mac or Linux; they are specific to running R on Windows.\n\n\n\nIf you are on a deadline and just need to get the job done this section should be all you need. Additional background and discussion is presented in later sections.\n\n\n\nTo read a text file with non ASCII encoding into R you should a) determine the encoding and b) read it in such a way that the information is re-encoded into UTF-8, and c) ignore the bug in the data.frame print method on Windows. Hopefully the encoding is specified in the documentation that accompanied your data. If not, you can guess the encoding using the stri_read_raw and stri_enc_detect functions in the stringi  package. You can ensure that the information is re-encoded to UTF-8 by using the readr package.\n\n\n\n\n\nFor example, I have two versions of a file containing numbers and Japanese characters: japanese_utf8.csv is encoded in UTF-8, and japanese_shiftjis.csv is encoded in SHIFT-JIS. We can read these files as follows on any platform (Windows, Linux, Mac):\n\n\nlibrary(readr)\noptions(stringsAsFactors = FALSE)\nread_csv(\"japanese_utf8.csv\",\n\t locale = locale(encoding = \"UTF-8\"))\nread_csv(\"japanese_shiftjis.csv\",\n\t locale = locale(encoding = \"SHIFT-JIS\"))\n\n\n\n    No.         \u767a\u884c\u65e5 \u671d\u5915\u520a     \u9762\u540d \u30da\u30fc\u30b8\n1 00001 2015\u5e7409\u670825\u65e5   \u9031\u520a \u9031\u520a\u671d\u65e5    022\n2 00002 2015\u5e7409\u670825\u65e5   \u9031\u520a \u9031\u520a\u671d\u65e5    018\n3 00003 2015\u5e7409\u670821\u65e5   \u671d\u520a   \uff13\u7dcf\u5408    003\n    No.         \u767a\u884c\u65e5 \u671d\u5915\u520a     \u9762\u540d \u30da\u30fc\u30b8\n1 00001 2015\u5e7409\u670825\u65e5   \u9031\u520a \u9031\u520a\u671d\u65e5    022\n2 00002 2015\u5e7409\u670825\u65e5   \u9031\u520a \u9031\u520a\u671d\u65e5    018\n3 00003 2015\u5e7409\u670821\u65e5   \u671d\u520a   \uff13\u7dcf\u5408    003\n\n\n\nOn Windows there is a bug in print.data.frame that causes data.frame's with UTF-8 encoded columns to be displayed incorrectly in non UTF-8 locales. Running the above example on Windows produces this:\n\n\n\n    No.         <U+767A><U+884C><U+65E5> <U+671D><U+5915><U+520A>                 <U+9762><U+540D> <U+30DA><U+30FC><U+30B8>\n1 00001 2015<U+5E74>09<U+6708>25<U+65E5>         <U+9031><U+520A> <U+9031><U+520A><U+671D><U+65E5>                      022\n2 00002 2015<U+5E74>09<U+6708>25<U+65E5>         <U+9031><U+520A> <U+9031><U+520A><U+671D><U+65E5>                      018\n3 00003 2015<U+5E74>09<U+6708>21<U+65E5>         <U+671D><U+520A>                3<U+7DCF><U+5408>                      003\n\n    No.         <U+767A><U+884C><U+65E5> <U+671D><U+5915><U+520A>                 <U+9762><U+540D> <U+30DA><U+30FC><U+30B8>\n1 00001 2015<U+5E74>09<U+6708>25<U+65E5>         <U+9031><U+520A> <U+9031><U+520A><U+671D><U+65E5>                      022\n2 00002 2015<U+5E74>09<U+6708>25<U+65E5>         <U+9031><U+520A> <U+9031><U+520A><U+671D><U+65E5>                      018\n3 00003 2015<U+5E74>09<U+6708>21<U+65E5>         <U+671D><U+520A>                3<U+7DCF><U+5408>                      003\n\n\nwhich looks terrible but does not actually indicate a problem. The information is encoded correctly, but due to a long-standing bug it is displayed incorrectly. You can check to see if the values are correct by converting the data.frame by (ab)using print.listof, e.g.,\n\n\nprint.listof(read_csv(\"japanese_shiftjis.csv\",\n\t\t      locale = locale(encoding = \"SHIFT-JIS\")))\n\n\n\nNo. :\n[1] \"00001\" \"00002\" \"00003\"\n\n\u767a\u884c\u65e5 :\n[1] \"2015\u5e7409\u670825\u65e5\" \"2015\u5e7409\u670825\u65e5\" \"2015\u5e7409\u670821\u65e5\"\n\n\u671d\u5915\u520a :\n[1] \"\u9031\u520a\" \"\u9031\u520a\" \"\u671d\u520a\"\n\n\u9762\u540d :\n[1] \"\u9031\u520a\u671d\u65e5\" \"\u9031\u520a\u671d\u65e5\" \"\uff13\u7dcf\u5408\"  \n\n\u30da\u30fc\u30b8 :\n[1] \"022\" \"018\" \"003\"\n\n\n\nTo recap: \n\n\nRegardless of platform (Windows, Mac Linux), use the readr package to read data into R. This will re-encode the contents of the file to UTF-8 for you. \n\nMake sure you specify the encoding using the locale argument as shown in the example above. \n\nIgnore the ugly print.data.frame bug and use print.listof to check that your data was imported correctly.\n\n\n\n\nThose wishing for more details about this issue can read on.\n\n\n\n\nWhat is the problem?\n\n\nThe problem is that the basic R functions for reading and writing data from and to files does no work in any reasonable way on Windows. If you are struggling with this you are not alone! There are numerous questions on stackoverflow, blog posts (e.g., this one by Rolf Fredheim, and another by Huidong Tian), and anguished mailing list posts. Thinking of the person-hours wasted on this issue over the years almost brings a tear to my eye. \n\n\n\nLet's try it, using some simplified data from a project I worked on last year. For illustration I've created two files containing a mix of English letters, numbers, and Japanese characters. I saved one version with UTF-8 encoding, and another with SHIFT-JIS. On Linux we can read both files easily, provided only that we correctly specify the encoding if the file is not already encoded in UTF-8:\n\n\nread.csv(\"japanese_utf8.csv\")\n\n\n\n  No.         \u767a\u884c\u65e5 \u671d\u5915\u520a     \u9762\u540d \u30da\u30fc\u30b8\n1   1 2015\u5e7409\u670825\u65e5   \u9031\u520a \u9031\u520a\u671d\u65e5     22\n2   2 2015\u5e7409\u670825\u65e5   \u9031\u520a \u9031\u520a\u671d\u65e5     18\n3   3 2015\u5e7409\u670821\u65e5   \u671d\u520a   \uff13\u7dcf\u5408      3\n\n\nread.csv(\"japanese_shiftjis.csv\", fileEncoding = \"SHIFT-JIS\")\n\n\n\n  No.         \u767a\u884c\u65e5 \u671d\u5915\u520a     \u9762\u540d \u30da\u30fc\u30b8\n1   1 2015\u5e7409\u670825\u65e5   \u9031\u520a \u9031\u520a\u671d\u65e5     22\n2   2 2015\u5e7409\u670825\u65e5   \u9031\u520a \u9031\u520a\u671d\u65e5     18\n3   3 2015\u5e7409\u670821\u65e5   \u671d\u520a   \uff13\u7dcf\u5408      3\n\n\n\nOn Windows things are much more difficult. Using read.csv with the default options does not work because read.csv assumes that the encoding of the file matches the Windows locale settings:\n\n\nread.csv(\"japanese_utf8.csv\")\n\n\n\n  No.         \u00e7.\u00ba\u00e8.\u0152\u00e6.. \u00e6\u0153.\u00e5..\u00e5.\u0160       \u00e9..\u00e5.. \u00e3\u0192\u0161\u00e3\u0192.\u00e3..\n1   1 2015\u00e5\u00b9\u00b409\u00e6\u0153\u02c625\u00e6\u2014\u00a5    \u00e9\u20ac\u00b1\u00e5\u02c6\u0160 \u00e9\u20ac\u00b1\u00e5\u02c6\u0160\u00e6\u0153\u009d\u00e6\u2014\u00a5        22\n2   2 2015\u00e5\u00b9\u00b409\u00e6\u0153\u02c625\u00e6\u2014\u00a5    \u00e9\u20ac\u00b1\u00e5\u02c6\u0160 \u00e9\u20ac\u00b1\u00e5\u02c6\u0160\u00e6\u0153\u009d\u00e6\u2014\u00a5        18\n3   3 2015\u00e5\u00b9\u00b409\u00e6\u0153\u02c621\u00e6\u2014\u00a5    \u00e6\u0153\u009d\u00e5\u02c6\u0160    \u00ef\u00bc\u201c\u00e7\u00b7\u008f\u00e5\u0090\u02c6         3\n\n\n\nTrying to tell R that the file is encoded in UTF-8 not a general solution because read.csv will then try to re-encode from UTF-8 to the native encoding, which may or may not work depending on the contents of the file. On my system trying to read a UTF-8 encoded file containing Japanese characters with the fileEncoding falls flat on its face:\n\nread.csv(\"japanese_utf8.csv\", fileEncoding = \"UTF-8\")\n\n\n\n[1] No. X  \n<0 rows> (or 0-length row.names)\nWarning messages:\n1: In read.table(file = file, header = header, sep = sep, quote = quote,  :\n  invalid input found on input connection 'japanese_utf8.csv'\n2: In read.table(file = file, header = header, sep = sep, quote = quote,  :\n  incomplete final line found by readTableHeader on 'japanese_utf8.csv'\n\n\n\n\nFinally, we might try the encoding argument rather than fileEncoding. This simply marks the strings with the specified encoding:\n\nread.csv(\"japanese_utf8.csv\", encoding = \"UTF-8\")\n\n\n\nread.csv(\"japanese_utf8.csv\", encoding = \"UTF-8\")\n  No.        X.U.767A..U.884C..U.65E5. X.U.671D..U.5915..U.520A.                X.U.9762..U.540D. X.U.30DA..U.30FC..U.30B8.\n1   1 2015<U+5E74>09<U+6708>25<U+65E5>          <U+9031><U+520A> <U+9031><U+520A><U+671D><U+65E5>                        22\n2   2 2015<U+5E74>09<U+6708>25<U+65E5>          <U+9031><U+520A> <U+9031><U+520A><U+671D><U+65E5>                        18\n3   3 2015<U+5E74>09<U+6708>21<U+65E5>          <U+671D><U+520A>                3<U+7DCF><U+5408>                         3\n\n\nThis kind of works, though you wouldn't know it from the output. As mentioned above, there is a bug in the print.data.frame function that prevents UTF-8 encoded text from displaying correctly. We can use another print method to see that the column values have been read in correctly:\n\nprint.listof(read.csv(\"japanese_utf8.csv\", encoding = \"UTF-8\"))\n\n\n\nNo. :\n[1] 1 2 3\n\nX.U.767A..U.884C..U.65E5. :\n[1] \"2015\u5e7409\u670825\u65e5\" \"2015\u5e7409\u670825\u65e5\" \"2015\u5e7409\u670821\u65e5\"\n\nX.U.671D..U.5915..U.520A. :\n[1] \"\u9031\u520a\" \"\u9031\u520a\" \"\u671d\u520a\"\n\nX.U.9762..U.540D. :\n[1] \"\u9031\u520a\u671d\u65e5\" \"\u9031\u520a\u671d\u65e5\" \"\uff13\u7dcf\u5408\"  \n\nX.U.30DA..U.30FC..U.30B8. :\n[1] 22 18  3\n\n\n\nUnfortunately there are two problems with this: first, the names of the columns have not been correctly encoded, and second, this will only work if your input data is in UTF-8 in the first place. Trying to apply this strategy to our SHIFT-JIS encoded file will not work at all because we cannot mark strings with arbitrary encoding, only with UTF-81. Trying to mark the string as SHIFT-JIS will silently fail:\n\nprint.listof(read.csv(\"japanese_shiftjis.csv\", encoding = \"SHIFT-JIS\"))\n\n\n\nNo. :\n[1] 1 2 3\n\nX...s.\u00fa :\n[1] \"2015\u201dN09\u0152\u017d25\u201c\u00fa\" \"2015\u201dN09\u0152\u017d25\u201c\u00fa\" \"2015\u201dN09\u0152\u017d21\u201c\u00fa\"\n\nX....\u0160. :\n[1] \"\u008fT\u0160\u00a7\" \"\u008fT\u0160\u00a7\" \"\u2019\u00a9\u0160\u00a7\"\n\nX.\u00ca.. :\n[1] \"\u008fT\u0160\u00a7\u2019\u00a9\u201c\u00fa\" \"\u008fT\u0160\u00a7\u2019\u00a9\u201c\u00fa\" \"\u201aR\u2018\u008d\u008d\u2021\"  \n\n\u0192y..\u0192W :\n[1] 22 18  3\n\n\n\nOuch! Why is this so hard? Can we make it suck less?\n\n\n\n\n\nEncoding in R\n\n\nBasically R gives you two ways of handling character encoding. You can use the default encoding of your OS, or you can use UTF-81. On OS X and Linux these options are often the same, since the default OS encoding is usually UTF-8; this is a great advantage because just about everything can be represented in UTF-8. On Windows there is no such luck. On my Windows 7 machine the default is \"Windows code page 1252\"; many characters (such as Japanese) cannot be represented in code page 1252. If I want to work with Japanese text in R on Windows I have two options; change my locale to Japanese, or I can convert strings to UTF-8 and mark them as such.\n\n\n\nIn some ways just changing your locale to one that can accommodate the data you are working with is the simplest approach. Again, on Mac and Linux the locale usually specifies UTF-8 encoding, so no changes are needed; things should just work as you would expect them to. On windows we can change the locale to match the data we are working with using the Sys.setlocale function. This sometimes works well; for example, we can read our UTF-8 and SHIFT-JIS encoded data on Windows as follows:\n\n\nsetlocale(\"LC_ALL\", \"English_United States.932\")\nread.csv(\"japanese_shiftjis.csv\")\nread.csv(\"japanese_utf8.csv\", fileEncoding = \"UTF-8\")\n\n\n\n[1] \"LC_COLLATE=English_United States.932;LC_CTYPE=English_United States.932;LC_MONETARY=English_United States.932;LC_NUMERIC=C;LC_TIME=English_United States.932\"\n\n  No.         \u767a\u884c\u65e5 \u671d\u5915\u520a     \u9762\u540d \u30da\u30fc\u30b8\n1   1 2015\u5e7409\u670825\u65e5   \u9031\u520a \u9031\u520a\u671d\u65e5     22\n2   2 2015\u5e7409\u670825\u65e5   \u9031\u520a \u9031\u520a\u671d\u65e5     18\n3   3 2015\u5e7409\u670821\u65e5   \u671d\u520a   \uff13\u7dcf\u5408      3\n\n  No.         \u767a\u884c\u65e5 \u671d\u5915\u520a     \u9762\u540d \u30da\u30fc\u30b8\n1   1 2015\u5e7409\u670825\u65e5   \u9031\u520a \u9031\u520a\u671d\u65e5     22\n2   2 2015\u5e7409\u670825\u65e5   \u9031\u520a \u9031\u520a\u671d\u65e5     18\n3   3 2015\u5e7409\u670821\u65e5   \u671d\u520a   \uff13\u7dcf\u5408      3\n\n\n\nThis works fine until we want to read some other kind of text in the same R session, and then we are right back to the same old problem. Another issue with this method is that it does not work in Rstudio unless the locale is set on startup; you cannot change the locale of a running session in Rstudio2.\n\n\n\nBecause the Sys.setlocale method only works for a subset of languages in any given session, our best bet is to read store everything in UTF-8 (and make sure it is marked as such). It is not convenient to do this using the read.table family of functions in R, but it is possible with some care:\n\nx <- read.csv(\"japanese_shiftjis.csv\", \n\t      encoding = \"UTF-8\", \n\t      check.names = FALSE # otherwise R will mangle the names\n\t      )\ncharcols <- !sapply(x, is.numeric)\nx[charcols] <- lapply(x[charcols], iconv, from = \"SHIFT-JIS\", to = \"UTF-8\")\nnames(x) <- iconv(names(x), from = \"SHIFT-JIS\", to = \"UTF-8\")\nprint.listof(x)\n\n\n\nNo. :\n[1] 1 2 3\n\n\u767a\u884c\u65e5 :\n[1] \"2015\u5e7409\u670825\u65e5\" \"2015\u5e7409\u670825\u65e5\" \"2015\u5e7409\u670821\u65e5\"\n\n\u671d\u5915\u520a :\n[1] \"\u9031\u520a\" \"\u9031\u520a\" \"\u671d\u520a\"\n\n\u9762\u540d :\n[1] \"\u9031\u520a\u671d\u65e5\" \"\u9031\u520a\u671d\u65e5\" \"\uff13\u7dcf\u5408\"  \n\n\u30da\u30fc\u30b8 :\n[1] 22 18  3\n\n\nOK it works, but honestly that too much work for something as simple as reading a .csv file into R. As suggested at the beginning of this post, a better strategy is to use the readr package because it will do the conversion to UTF-8 for you:\n\n\nprint.listof(read_csv(\"arabic_utf-8.csv\"), locale = locale(encoding = \"UTF-8\"))\nprint.listof(read_csv(\"japanese_utf8.csv\"), locale = locale(encoding = \"UTF-8\"))\nprint.listof(read_csv(\"japanese_shiftjis.csv\"), locale = locale(encoding = \"SHIFT-JIS\"))\n\n\n\nX5 :\n[1] \"1895-01-02\" \"1895-01-07\" \"1895-01-16\"\nX8 :\n[1] \"\u0627\u0635\u0644\u0649\" \"\u0627\u0635\u0644\u0649\" \"\u0627\u0635\u0644\u0649\"\nX12 :\n[1] \"\u0648\u0642\u0627\u0626\u0639\" \"\u0648\u0642\u0627\u0626\u0639\" \"\u0648\u0642\u0627\u0626\u0639\"\n\nNo. :\n[1] \"00001\" \"00002\" \"00003\"\n\u767a\u884c\u65e5 :\n[1] \"2015\u5e7409\u670825\u65e5\" \"2015\u5e7409\u670825\u65e5\" \"2015\u5e7409\u670821\u65e5\"\n\u671d\u5915\u520a :\n[1] \"\u9031\u520a\" \"\u9031\u520a\" \"\u671d\u520a\"\n\u9762\u540d :\n[1] \"\u9031\u520a\u671d\u65e5\" \"\u9031\u520a\u671d\u65e5\" \"\uff13\u7dcf\u5408\"  \n\u30da\u30fc\u30b8 :\n[1] \"022\" \"018\" \"003\"\n\n\nNo. :\n[1] \"00001\" \"00002\" \"00003\"\n\u767a\u884c\u65e5 :\n[1] \"2015\u5e7409\u670825\u65e5\" \"2015\u5e7409\u670825\u65e5\" \"2015\u5e7409\u670821\u65e5\"\n\u671d\u5915\u520a :\n[1] \"\u9031\u520a\" \"\u9031\u520a\" \"\u671d\u520a\"\n\u9762\u540d :\n[1] \"\u9031\u520a\u671d\u65e5\" \"\u9031\u520a\u671d\u65e5\" \"\uff13\u7dcf\u5408\"  \n\u30da\u30fc\u30b8 :\n[1] \"022\" \"018\" \"003\"\n\n\n\n\n\nFiles\n\n\nHere are the example data files and code and needed to run the examples in this post.\n\n\n\n\nFootnotes: \n\n\n1 \nWe can also mark strings as encoded in latin1, but that is not useful if you take my advice and store everything in UTF-8.\n\n\n2 \nSee https://support.rstudio.com/hc/en-us/articles/200532197-Character-Encoding",
      "tags": "Encoding,Files,R,SHIFT-JIS,UTF-8",
      "url": "http://people.fas.harvard.edu/~izahn/posts/reading-data-with-non-native-encoding-in-r/"
    }
  ]
}
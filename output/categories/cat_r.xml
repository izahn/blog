<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ista Zahn (R)</title><link>http://people.fas.harvard.edu/~izahn/</link><description></description><atom:link href="http://people.fas.harvard.edu/~izahn/categories/cat_r.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Fri, 12 Aug 2016 20:38:53 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Extracting content from .pdf files</title><link>http://people.fas.harvard.edu/~izahn/posts/extracting-content-from-pdf-files/</link><dc:creator>Ista Zahn</dc:creator><description>&lt;p&gt;
One of common question I get as a &lt;a href="http://dss.iq.harvard.edu"&gt;data science consultant&lt;/a&gt; involves extracting content from &lt;code&gt;.pdf&lt;/code&gt; files. In the best-case scenario the content can be extracted to consistently formatted text files and parsed from there into a usable form. In the worst case the file will need to be run through an optical character recognition (OCR) program to extract the text.
&lt;/p&gt;

&lt;div id="outline-container-sec-1" class="outline-2"&gt;
&lt;h2 id="sec-1"&gt;Overview of available tools&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-1"&gt;
&lt;p&gt;
For years &lt;code&gt;pdftotext&lt;/code&gt; from the &lt;a href="https://poppler.freedesktop.org/"&gt;poppler&lt;/a&gt; project was my go-to answer for the easy case. This is still a good option, especially on Mac (using &lt;a href="http://brew.sh"&gt;homebrew&lt;/a&gt;) or Linux where installation is easy. Windows users can install poppler binaries from &lt;a href="http://blog.alivate.com.au/poppler-windows/"&gt;&lt;/a&gt;&lt;a href="http://blog.alivate.com.au/poppler-windows/"&gt;http://blog.alivate.com.au/poppler-windows/&lt;/a&gt; (make sure to &lt;a href="http://www.computerhope.com/issues/ch000549.htm"&gt;add the &lt;code&gt;bin&lt;/code&gt; directory to your &lt;code&gt;PATH&lt;/code&gt;&lt;/a&gt;). More recently I've been using the excellent &lt;a href="https://github.com/ropensci/pdftools"&gt;pdftools&lt;/a&gt; packge in &lt;a href="http://r-project.org"&gt;R&lt;/a&gt; to more easily extract and manipulate text stored in &lt;code&gt;.pdf&lt;/code&gt; files.
&lt;/p&gt;

&lt;p&gt;
In the more difficult case where the pdf contains images rather than text it is necessary to use optical character recognition (OCR) to recover the text. This can be achieved using point-and-click applications like &lt;a href="http://www.paperfile.net/"&gt;freeOCR&lt;/a&gt;, &lt;a href="https://acrobat.adobe.com/us/en/acrobat.html"&gt;Adobe Acrobat&lt;/a&gt; or &lt;a href="https://www.abbyy.com/"&gt;ABBYY&lt;/a&gt;. ABBYY even has a convenient &lt;a href="http://ocrsdk.com/"&gt;cloud OCR service&lt;/a&gt; that can be easily accessed from R using the &lt;a href="https://cran.rstudio.com/web/packages/abbyyR/index.html"&gt;abbyyR&lt;/a&gt; package. If you don't have a license for one of these expensive OCR solutions, or if you prefer something you easily can script from the command line, &lt;a href="https://github.com/tesseract-ocr/tesseract"&gt;tesseract&lt;/a&gt; is a very good option.
&lt;/p&gt;

&lt;!-- TEASER_END --&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-2" class="outline-2"&gt;
&lt;h2 id="sec-2"&gt;An easy example&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-2"&gt;
&lt;p&gt;
In the case where the &lt;code&gt;pdf&lt;/code&gt; contains text, extracting it is usually not too difficult. As an example, consider the &lt;code&gt;.pdf&lt;/code&gt; file at &lt;a href="http://www.cdc.gov/nchs/data/nvsr/nvsr65/nvsr65_05.pdf"&gt;http://www.cdc.gov/nchs/data/nvsr/nvsr65/nvsr65_05.pdf&lt;/a&gt;. Wouldn't it be nice to extract the data in those tables so we can visualize it in different ways?&lt;sup&gt;&lt;a id="fnr.1" name="fnr.1" class="footref" href="http://people.fas.harvard.edu/~izahn/posts/extracting-content-from-pdf-files/#fn.1"&gt;1&lt;/a&gt;&lt;/sup&gt; We can, using the &lt;code&gt;pdftotext&lt;/code&gt; utility provided by the poppler project.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl -o nvsr65_05.pdf http://www.cdc.gov/nchs/data/nvsr/nvsr65/nvsr65_05.pdf
pdftotext nvsr65_05.pdf nvsr65_05.txt
head nvsr65_05.txt
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
National Vital
Statistics Reports
Volume 65, Number 5

June 30, 2016

Deaths: Leading Causes for 2014
by Melonie Heron, Ph.D., Division of Vital Statistics

Abstract
&lt;/pre&gt;

&lt;p&gt;
We can achieve a similar result in R using the &lt;code&gt;pdftools&lt;/code&gt; package.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;pdftools&lt;span class="p"&gt;)&lt;/span&gt;
nvsr65_05 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; pdf_text&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"http://www.cdc.gov/nchs/data/nvsr/nvsr65/nvsr65_05.pdf"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kp"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;strsplit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;nvsr65_05&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="s"&gt;"\n"&lt;/span&gt;&lt;span class="p"&gt;)[[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[1] "National Vital"                                                                                                                          
[2] "Statistics Reports"                                                                                                                      
[3] "Volume 65, Number 5                                                                                                        June 30, 2016"
[4] "Deaths: Leading Causes for 2014"                                                                                                         
[5] "by Melonie Heron, Ph.D., Division of Vital Statistics"                                                                                   
[6] "Abstract                                                                 Introduction"
&lt;/pre&gt;

&lt;p&gt;
Once the text has been liberated from the pdf we can parse it into a usable form and proceed from there. This is often tedious and delicate work, but with some care the data can usually be coerced into shape. For example, table G can be extracted using a few well crafted regular expressions.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;readr&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;stringr&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;dplyr&lt;span class="p"&gt;)&lt;/span&gt;
table_data &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; nvsr65_05&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="m"&gt;14&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  str_split&lt;span class="p"&gt;(&lt;/span&gt;pattern &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"\n"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class="kp"&gt;unlist&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  str_subset&lt;span class="p"&gt;(&lt;/span&gt;pattern &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"^[^…].*(\\. ){5}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  str_c&lt;span class="p"&gt;(&lt;/span&gt;collapse &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"\n"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  read_table&lt;span class="p"&gt;(&lt;/span&gt;col_names &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  mutate&lt;span class="p"&gt;(&lt;/span&gt;X2 &lt;span class="o"&gt;=&lt;/span&gt; str_replace_all&lt;span class="p"&gt;(&lt;/span&gt;X2&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"(\\. )*"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;""&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
	 X5 &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kp"&gt;rep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Neonatal"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"Postnatal"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; each &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  set_names&lt;span class="p"&gt;(&lt;/span&gt;value &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"rank"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"cause_of_death"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"deaths"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"percent"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"group"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
table_data
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union
 Error in function_list[[k]](value) : could not find function "set_names"
Error: object 'table_data' not found
&lt;/pre&gt;

&lt;p&gt;
Once the data has been liberated from the &lt;code&gt;.pdf&lt;/code&gt; it can be used anyway we like–for example, we can convert the table to a graph to make it easier to compare the prevelance of different causes.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ggplot2&lt;span class="p"&gt;)&lt;/span&gt;
ggplot&lt;span class="p"&gt;(&lt;/span&gt;mutate&lt;span class="p"&gt;(&lt;/span&gt;table_data&lt;span class="p"&gt;,&lt;/span&gt; cause_of_death &lt;span class="o"&gt;=&lt;/span&gt; reorder&lt;span class="p"&gt;(&lt;/span&gt;cause_of_death&lt;span class="p"&gt;,&lt;/span&gt; deaths&lt;span class="p"&gt;)),&lt;/span&gt;
       aes&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; cause_of_death&lt;span class="p"&gt;,&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; percent&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
  geom_bar&lt;span class="p"&gt;(&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;fill &lt;span class="o"&gt;=&lt;/span&gt; deaths&lt;span class="p"&gt;),&lt;/span&gt; stat&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"identity"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
  facet_wrap&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;group&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
  coord_flip&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
  theme_minimal&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="http://people.fas.harvard.edu/~izahn/posts/extracting-content-from-pdf-files/cod.png" alt="cod.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-3" class="outline-2"&gt;
&lt;h2 id="sec-3"&gt;A more difficult example&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-3"&gt;
&lt;p&gt;
The example above was relatively easy, because the pdf contained information stored as text. For many older pdfs (especialy old scanned documents) the information will instead be stored as images. This makes life much more difficult, but with a little work the data can be liberated. As mentioned in &lt;a href="http://people.fas.harvard.edu/~izahn/posts/extracting-content-from-pdf-files/#sec-1"&gt;Overview of available tools&lt;/a&gt; there are several optinos to choose from. In this example I'm going to use &lt;a href="https://github.com/tesseract-ocr/tesseract"&gt;tesseract&lt;/a&gt; because it is free and easily scriptable.
&lt;/p&gt;

&lt;p&gt;
The tesseract program cannot process pdf files directly, so the first step is to convert each page of the pdf to an image. This can be done using the &lt;code&gt;pdftocairo&lt;/code&gt; utility (part of the &lt;a href="https://poppler.freedesktop.org/"&gt;poppler&lt;/a&gt; project). The information I want is on pages 32 to 186, so I'll convert just those pages.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; ../files/example_files/blog/pdf_extraction
pdftocairo -png BLS_employment_costs_documentation.pdf -f &lt;span class="m"&gt;32&lt;/span&gt; -l 186
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Once the pdf pages have been converted to an image format (&lt;code&gt;.png&lt;/code&gt; in this example) they can be converted to text using &lt;code&gt;tesseract&lt;/code&gt;. The quality of the conversion depends on lots of things, but mostly the quality of the original images. In this example the quality is variable and generally poor, but useful information can still be extracted.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; ../files/example_files/blog/pdf_extraction
&lt;span class="k"&gt;for&lt;/span&gt; imageFile in *.png
   &lt;span class="k"&gt;do&lt;/span&gt;
   tesseract &lt;span class="se"&gt;\&lt;/span&gt;
   -c &lt;span class="nv"&gt;tessedit_char_whitelist&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 :/()-"&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
		     &lt;span class="nv"&gt;$imageFile&lt;/span&gt; &lt;span class="nv"&gt;$imageFile&lt;/span&gt;
   &lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now that we have freed the information from the confines of the &lt;code&gt;.pdf&lt;/code&gt; file we will usualy want to re-assemble the information extracted from each page and clean things up. I'm using R for this, though many of my colleagues prefer python for this sort of thing.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;text_data &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;list.files&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"../files/example_files/blog/pdf_extraction"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			pattern &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"\\.txt$"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			full.names &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class="kp"&gt;lapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;FUN &lt;span class="o"&gt;=&lt;/span&gt; read_lines&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class="kp"&gt;lapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;FUN &lt;span class="o"&gt;=&lt;/span&gt; str_subset&lt;span class="p"&gt;,&lt;/span&gt; pattern &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"(^DATA DESCRIPTION:)|(^SOURCE:)|(^SIZE:)|(^TYPE:)"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class="kp"&gt;lapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;FUN &lt;span class="o"&gt;=&lt;/span&gt; str_split_fixed&lt;span class="p"&gt;,&lt;/span&gt; pattern &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;": *"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; n &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class="kp"&gt;lapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;FUN &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    dtmp &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;data.frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;as.list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;[,&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; stringsAsFactors &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="kp"&gt;names&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;dtmp&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; x&lt;span class="p"&gt;[,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;dtmp&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;})&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  bind_rows&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="kp"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;text_data&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
                                        DATA DESCRIPTION
1  Schedule (Sele5:1i2 x-1)yuxgm:glzzezy-    g m:   - nu
2                            SchedulejSelem-leyugqberm  
3                                                   &amp;lt;NA&amp;gt;
4                               City Size Classification
5 Original Standgrjiqdqstrial Classificatigg- (SIC) pcde
6        Original Egtabhshcpegt Size Classification u - 
                     SOURCE                        SIZE        TYPE
1 iEEC/DCC Qqntrol File - m  CHARACTERm): 5 BYTE(S) : 5 Character I
2                      &amp;lt;NA&amp;gt;    CHARACTERGL: 5 BYTE(5) : : Character
3     EEC/DCC Contr-ol File     CHARACTERGH 2 BYTE(S) :   Character
4      EEC/DCC Controi File I CHARACTERS) : 1 BYTE(S) : i Character
5      EEC/DOC Control File                        &amp;lt;NA&amp;gt;        &amp;lt;NA&amp;gt;
6      EEC/DOC Control File                        &amp;lt;NA&amp;gt; 0 Character
&lt;/pre&gt;

&lt;p&gt;
It is cleary that many characters were not recognized correctly. However, there is enough imformation to be useful, especially if we spend a little more effort cleaning things up. The &lt;a href="https://github.com/ropensci/hunspell#readme"&gt;hunspell&lt;/a&gt; package in R can be useful if you know the recovered information should be dictionary words.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;hunspell&lt;span class="p"&gt;)&lt;/span&gt;
text_data&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kp"&gt;is.na&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;text_data&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="s"&gt;""&lt;/span&gt;
text_data&lt;span class="o"&gt;$&lt;/span&gt;TYPE &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; str_to_lower&lt;span class="p"&gt;(&lt;/span&gt;text_data&lt;span class="o"&gt;$&lt;/span&gt;TYPE&lt;span class="p"&gt;)&lt;/span&gt;
text_data&lt;span class="o"&gt;$&lt;/span&gt;TYPE &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; str_replace_all&lt;span class="p"&gt;(&lt;/span&gt;text_data&lt;span class="o"&gt;$&lt;/span&gt;TYPE&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"(^| ).( |$)"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
type_bad_words &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; hunspell&lt;span class="p"&gt;(&lt;/span&gt;str_c&lt;span class="p"&gt;(&lt;/span&gt;text_data&lt;span class="o"&gt;$&lt;/span&gt;TYPE&lt;span class="p"&gt;,&lt;/span&gt; collapse &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;" "&lt;/span&gt;&lt;span class="p"&gt;))[[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
type_replacement_words &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;sapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;hunspell_suggest&lt;span class="p"&gt;(&lt;/span&gt;type_bad_words&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; x&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
type_bad_words &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; str_c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"(^|\\W)"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;type_bad_words&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"(\\W|$)"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; sep &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
type_replacement_words &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; str_c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"\\1"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; type_replacement_words&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"\\2"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="kr"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;i &lt;span class="kr"&gt;in&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="kp"&gt;length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;type_bad_words&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  text_data&lt;span class="o"&gt;$&lt;/span&gt;TYPE &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; str_replace_all&lt;span class="p"&gt;(&lt;/span&gt;text_data&lt;span class="o"&gt;$&lt;/span&gt;TYPE&lt;span class="p"&gt;,&lt;/span&gt;
				    type_bad_words&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;],&lt;/span&gt;
				    type_replacement_words&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

text_data&lt;span class="o"&gt;$&lt;/span&gt;TYPE &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; str_replace_all&lt;span class="p"&gt;(&lt;/span&gt;text_data&lt;span class="o"&gt;$&lt;/span&gt;TYPE&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;" +"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;" "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
text_data&lt;span class="o"&gt;$&lt;/span&gt;TYPE &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; str_trim&lt;span class="p"&gt;(&lt;/span&gt;text_data&lt;span class="o"&gt;$&lt;/span&gt;TYPE&lt;span class="p"&gt;,&lt;/span&gt; side &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;'both'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Even after all that there are still some errors, but we've managed to correctly retrieve the type information for the majority of the variables in this dictionary.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;count&lt;span class="p"&gt;(&lt;/span&gt;text_data&lt;span class="p"&gt;,&lt;/span&gt; TYPE&lt;span class="p"&gt;,&lt;/span&gt; sort &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
# A tibble: 10 x 2
             TYPE     n
            &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
1       character    65
2   fixed decimal    42
3                    41
4      charioteer     1
5      chm-gage:-     1
6  fixed decimal)     1
7  fixed-decimal:     1
8   fixed deem-ll     1
9     hexadecimal     1
10     tee-rater-     1
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-4" class="outline-2"&gt;
&lt;h2 id="sec-4"&gt;Concluding remarks&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-4"&gt;
&lt;p&gt;
I covered a lot of ground in this post, from graphical OCR programs to spell checking packages in R. The take-away messages as I seem them are:
&lt;/p&gt;
&lt;ol class="org-ol"&gt;
&lt;li&gt;The &lt;a href="https://github.com/ropensci/hunspell#readme"&gt;pdftools&lt;/a&gt; package is great news for R users who need to work with &lt;code&gt;.pdf&lt;/code&gt; files. It makes it easy to extract and manipulate pdf content and metadata no matter what operating system you use, all from within R.
&lt;/li&gt;
&lt;li&gt;The &lt;a href="https://github.com/tesseract-ocr/tesseract"&gt;tesseract&lt;/a&gt; OCR program is very capable, but don't expect miracles. If the original image quality is poor you can expect to spend a lot of time cleaning up the resulting text.
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="footnotes"&gt;
&lt;h2 class="footnotes"&gt;Footnotes: &lt;/h2&gt;
&lt;div id="text-footnotes"&gt;

&lt;div class="footdef"&gt;&lt;sup&gt;&lt;a id="fn.1" name="fn.1" class="footnum" href="http://people.fas.harvard.edu/~izahn/posts/extracting-content-from-pdf-files/#fnr.1"&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;p class="footpara"&gt;
I'm sure these data are available somewhere in more convenient form, but a) I couldn't find them and b) I needed an example pdf with interesting content.
&lt;/p&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;/div&gt;</description><category>OCR</category><category>pdf</category><category>R</category><guid>http://people.fas.harvard.edu/~izahn/posts/extracting-content-from-pdf-files/</guid><pubDate>Wed, 27 Jul 2016 22:13:28 GMT</pubDate></item><item><title>Useless but fun R packages</title><link>http://people.fas.harvard.edu/~izahn/posts/useless-but-fun-r-packages/</link><dc:creator>Ista Zahn</dc:creator><description>&lt;p&gt;
&lt;a href="http://r-project.org"&gt;R&lt;/a&gt; is useful for many things. But, it is not only useful! There is plenty of fun to be had as well. In celebration of Summer I'm going to take a look at some useless (but fun!) R packages.
&lt;/p&gt;

&lt;!-- TEASER_END --&gt;

&lt;div id="outline-container-sec-1" class="outline-2"&gt;
&lt;h2 id="sec-1"&gt;Fortune teller&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-1"&gt;
&lt;p&gt;
&lt;a href="https://cran.r-project.org/web/packages/fortunes/index.html"&gt;fortunes&lt;/a&gt; is probably the best-known "just for fun" R package. It is maintained by Achim Zeileis and features contributions from such R luminaries as Peter Dalgaard, Uwe Ligges, Kevin Wright, and many others. The &lt;code&gt;fortunes&lt;/code&gt; package been amusing bored statisticians and programmers since 2004. Since that time the &lt;code&gt;fortunes&lt;/code&gt; package developers have been selecting amusing quotes from the &lt;a href="https://stat.ethz.ch/mailman/listinfo/r-help"&gt;R-help mailing list&lt;/a&gt; and other sources and compiling them for your enjoyment. Let's take a look.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;## install.packages("fortunes") # if you don't already have it&lt;/span&gt;
&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;fortunes&lt;span class="p"&gt;)&lt;/span&gt;
fortune&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
When in doubt, keep adding slashes until it works.
   -- Joran Elias (on how to escape a backslash in R)
      Stackoverflow (March 2015)
&lt;/pre&gt;

&lt;p&gt;
When called without arguments, the &lt;code&gt;fortune&lt;/code&gt; function will select a random fortune. Calling &lt;code&gt;fortune&lt;/code&gt; again will select another random quote:
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;fortune&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
RAM is cheap and thinking hurts.
   -- Uwe Ligges (about memory requirements in R)
      R-help (June 2007)
&lt;/pre&gt;

&lt;p&gt;
If you want to specify a particular quote you can do so by number or by character search:
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;fortune&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;204&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
fortune&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"memory"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
memory problems (not me. my pc!)
   -- Sara Mouro (subject line for an R-help request)
      R-help (January 2008)

RAM is cheap and thinking hurts.
   -- Uwe Ligges (about memory requirements in R)
      R-help (June 2007)
&lt;/pre&gt;

&lt;p&gt;
That's about it. Well, there are some other options, see &lt;code&gt;?fortune&lt;/code&gt; for the details.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-2" class="outline-2"&gt;
&lt;h2 id="sec-2"&gt;Cow says what?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-2"&gt;
&lt;p&gt;
If you are a Unix user of a certain age you have no doubt heard of the famous &lt;a href="https://en.wikipedia.org/wiki/Cowsay"&gt;cowsay&lt;/a&gt; program. Now R users can join the fun with the &lt;a href="https://github.com/sckott/cowsay"&gt;cowsay R package&lt;/a&gt; by Scott Chamberlain. Like the &lt;code&gt;fortunes&lt;/code&gt; package, &lt;code&gt;cowsay&lt;/code&gt; exports just one function; &lt;code&gt;say&lt;/code&gt;. Let's take a look:
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;## install.packages("cowsay")&lt;/span&gt;
&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;cowsay&lt;span class="p"&gt;)&lt;/span&gt;
say&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Hello world!"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
 -------------- 
Hello world! 
 --------------
    \
      \
        \
            |\___/|
          ==) ^Y^ (==
            \  ^  /
             )=*=(
            /     \
            |     |
           /| | | |\
           \| | |_|/\
      jgs  //_// ___/
               \_)
&lt;/pre&gt;

&lt;p&gt;
Cute, but I was led to believe there would be a cow involved! 
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;say&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Moo may represent an idea, but only the cow knows.\n --Mason Cooley"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    by &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"cow"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
 ----- 
Moo may represent an idea, but only the cow knows.
 --Mason Cooley 
 ------ 
    \   ^__^ 
     \  (oo)\ ________ 
        (__)\         )\ /\ 
             ||------w|
             ||      ||
&lt;/pre&gt;

&lt;p&gt;
There is no option to randomly select an animal, but we can achieve that ourselves easily enough.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;someone_say_hello &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  animal &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;names&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;animals&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  say&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;paste&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"Hello, I'm a "&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; animal&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"."&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; collapse &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;""&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; by &lt;span class="o"&gt;=&lt;/span&gt; animal&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
someone_say_hello&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
 ----- 
Hello, I'm a  bigcat . 
 ------ 
    \   
     \
                \`*-.
                 )  _`-.
                .  : `. .
                : _   '  \
                ; *` _.   `*-._
                `-.-'          `-.
                  ;       `       `.
                  :.       .       \
                  .\  .   :   .-'   .
                  '  `+.;  ;  '      :
                  :  '  |    ;       ;-.
                  ; '   : :`-:     _.`* ;
               .*' /  .*' ; .*`- +'  `*'
     [bug]     `*-*   `*-*  `*-*'
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-3" class="outline-2"&gt;
&lt;h2 id="sec-3"&gt;Putting it all together&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-3"&gt;
&lt;p&gt;
When I teach R I emphasize composability. That is, unlike some other statistics packages, R enables you to take the output from one function and pass in on to another. We can take advantage of the excellent composability R provides to do useful things like extract coefficients from a list of model fits and put them into a LaTeX table. Or we can use it to do useless things like making a cow tell us our fortune.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;someone_say_my_fortune &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  animal &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; animal &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;names&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;animals&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  say&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;paste&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;fortune&lt;span class="p"&gt;(),&lt;/span&gt; collapse &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"\n"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; by &lt;span class="o"&gt;=&lt;/span&gt; animal&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
someone_say_my_fortune&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
 ------------- 
Only with a very high signal to noise ratio (e.g., high true R^2) can 
torturing data lead to a confession to something other than what the 
analyst wants to hear.
Frank Harrell
NA
R-help
April 2010 
 -------------- 
              \   
               \  
                \
_____________________                              _____________________
`-._                 \           |\__/|           /                 _.-'
    \                 \          |    |          /                 /
     \                 `-_______/      \_______-'                 /
      |                                                          |
      |                                                          |
      |                                                          |
      /                                                          \
     /_____________                                  _____________\
                   `----._                    _.----'
                          `--.            .--'
                              `-.      .-'
                                 \    / :F_P:
                                  \  /
                                   \/
&lt;/pre&gt;

&lt;p&gt;
Because &lt;code&gt;fortune&lt;/code&gt; gives a random quote each time, and we randomly select animals each time, we will get a surprising new delight every time we call the &lt;code&gt;someone_say_my_fortune&lt;/code&gt; function.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;someone_say_my_fortune&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
 ----- 
There's an informal tradition that those announcements [about R releases]
contain at least one mistake, but apparently I forgot this time, so users 
have to make up their own....
Peter Dalgaard
about an apparent non-bug report in his former R-announce message
R-help
December 2009 
 ------ 
    \   
     \
         _
       _/ }
      `&amp;gt;' \
      `|   \
       |   /'-.     .-.
        \'     ';`--' .'
         \'.    `'-./
          '.`-..-;`
            `;-..'
            _| _|
            /` /` [nosig]
&lt;/pre&gt;

&lt;p&gt;
If you want to get really silly about it, you could call that function in your &lt;a href="https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Customizing-the-environment"&gt;.Rprofile&lt;/a&gt;. Or, if you are package author you could add some spice to your warning and error messages by having an ASCII art animal say them. Go forth and have fun!
&lt;/p&gt;

&lt;p&gt;
If you know of other useless (but fun!) R packages let me know in the comments. 
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>fun</category><category>R</category><guid>http://people.fas.harvard.edu/~izahn/posts/useless-but-fun-r-packages/</guid><pubDate>Tue, 21 Jun 2016 00:44:13 GMT</pubDate></item><item><title>Escaping from character encoding hell in R on Windows</title><link>http://people.fas.harvard.edu/~izahn/posts/reading-data-with-non-native-encoding-in-r/</link><dc:creator>Ista Zahn</dc:creator><description>&lt;p&gt;
Note: the title of this post was inspired by &lt;a href="http://stackoverflow.com/questions/18789330/r-on-windows-character-encoding-hell"&gt;this question on stackoverflow&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
This section gives the basic facts and recommendations for importing files with arbitrary encoding on Windows. The issues described here by and large to not apply on Mac or Linux; they are specific to running &lt;a href="http://people.fas.harvard.edu/~izahn/r-project.org"&gt;R&lt;/a&gt; on Windows.
&lt;/p&gt;

&lt;p&gt;
If you are on a deadline and just need to get the job done this section should be all you need. Additional background and discussion is presented in later sections.
&lt;/p&gt;

&lt;p&gt;
To read a text file with non ASCII encoding into R you should a) determine the encoding and b) read it in such a way that the information is re-encoded into UTF-8, and c) ignore the bug in the &lt;code&gt;data.frame&lt;/code&gt; print method on Windows. Hopefully the encoding is specified in the documentation that accompanied your data. If not, you can guess the encoding using the &lt;code&gt;stri_read_raw&lt;/code&gt; and &lt;code&gt;stri_enc_detect&lt;/code&gt; functions in the &lt;a href="http://www.gagolewski.com/software/stringi/"&gt;stringi&lt;/a&gt;  package. You can ensure that the information is re-encoded to UTF-8 by using the &lt;a href="https://github.com/hadley/readr"&gt;readr&lt;/a&gt; package.
&lt;/p&gt;

&lt;!-- TEASER_END --&gt;

&lt;p&gt;
For example, I have two versions of a file containing numbers and Japanese characters: &lt;code&gt;japanese_utf8.csv&lt;/code&gt; is encoded in UTF-8, and &lt;code&gt;japanese_shiftjis.csv&lt;/code&gt; is encoded in SHIFT-JIS. We can read these files as follows on any platform (Windows, Linux, Mac):
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;readr&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kp"&gt;options&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;stringsAsFactors &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
read_csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_utf8.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	 locale &lt;span class="o"&gt;=&lt;/span&gt; locale&lt;span class="p"&gt;(&lt;/span&gt;encoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"UTF-8"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
read_csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_shiftjis.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	 locale &lt;span class="o"&gt;=&lt;/span&gt; locale&lt;span class="p"&gt;(&lt;/span&gt;encoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"SHIFT-JIS"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
    No.         発行日 朝夕刊     面名 ページ
1 00001 2015年09月25日   週刊 週刊朝日    022
2 00002 2015年09月25日   週刊 週刊朝日    018
3 00003 2015年09月21日   朝刊   ３総合    003
    No.         発行日 朝夕刊     面名 ページ
1 00001 2015年09月25日   週刊 週刊朝日    022
2 00002 2015年09月25日   週刊 週刊朝日    018
3 00003 2015年09月21日   朝刊   ３総合    003
&lt;/pre&gt;

&lt;p&gt;
On Windows there is a bug in &lt;code&gt;print.data.frame&lt;/code&gt; that causes &lt;code&gt;data.frame&lt;/code&gt;'s with UTF-8 encoded columns to be displayed incorrectly in non UTF-8 locales. Running the above example on Windows produces this:
&lt;/p&gt;

&lt;pre class="example"&gt;
    No.         &amp;lt;U+767A&amp;gt;&amp;lt;U+884C&amp;gt;&amp;lt;U+65E5&amp;gt; &amp;lt;U+671D&amp;gt;&amp;lt;U+5915&amp;gt;&amp;lt;U+520A&amp;gt;                 &amp;lt;U+9762&amp;gt;&amp;lt;U+540D&amp;gt; &amp;lt;U+30DA&amp;gt;&amp;lt;U+30FC&amp;gt;&amp;lt;U+30B8&amp;gt;
1 00001 2015&amp;lt;U+5E74&amp;gt;09&amp;lt;U+6708&amp;gt;25&amp;lt;U+65E5&amp;gt;         &amp;lt;U+9031&amp;gt;&amp;lt;U+520A&amp;gt; &amp;lt;U+9031&amp;gt;&amp;lt;U+520A&amp;gt;&amp;lt;U+671D&amp;gt;&amp;lt;U+65E5&amp;gt;                      022
2 00002 2015&amp;lt;U+5E74&amp;gt;09&amp;lt;U+6708&amp;gt;25&amp;lt;U+65E5&amp;gt;         &amp;lt;U+9031&amp;gt;&amp;lt;U+520A&amp;gt; &amp;lt;U+9031&amp;gt;&amp;lt;U+520A&amp;gt;&amp;lt;U+671D&amp;gt;&amp;lt;U+65E5&amp;gt;                      018
3 00003 2015&amp;lt;U+5E74&amp;gt;09&amp;lt;U+6708&amp;gt;21&amp;lt;U+65E5&amp;gt;         &amp;lt;U+671D&amp;gt;&amp;lt;U+520A&amp;gt;                3&amp;lt;U+7DCF&amp;gt;&amp;lt;U+5408&amp;gt;                      003

    No.         &amp;lt;U+767A&amp;gt;&amp;lt;U+884C&amp;gt;&amp;lt;U+65E5&amp;gt; &amp;lt;U+671D&amp;gt;&amp;lt;U+5915&amp;gt;&amp;lt;U+520A&amp;gt;                 &amp;lt;U+9762&amp;gt;&amp;lt;U+540D&amp;gt; &amp;lt;U+30DA&amp;gt;&amp;lt;U+30FC&amp;gt;&amp;lt;U+30B8&amp;gt;
1 00001 2015&amp;lt;U+5E74&amp;gt;09&amp;lt;U+6708&amp;gt;25&amp;lt;U+65E5&amp;gt;         &amp;lt;U+9031&amp;gt;&amp;lt;U+520A&amp;gt; &amp;lt;U+9031&amp;gt;&amp;lt;U+520A&amp;gt;&amp;lt;U+671D&amp;gt;&amp;lt;U+65E5&amp;gt;                      022
2 00002 2015&amp;lt;U+5E74&amp;gt;09&amp;lt;U+6708&amp;gt;25&amp;lt;U+65E5&amp;gt;         &amp;lt;U+9031&amp;gt;&amp;lt;U+520A&amp;gt; &amp;lt;U+9031&amp;gt;&amp;lt;U+520A&amp;gt;&amp;lt;U+671D&amp;gt;&amp;lt;U+65E5&amp;gt;                      018
3 00003 2015&amp;lt;U+5E74&amp;gt;09&amp;lt;U+6708&amp;gt;21&amp;lt;U+65E5&amp;gt;         &amp;lt;U+671D&amp;gt;&amp;lt;U+520A&amp;gt;                3&amp;lt;U+7DCF&amp;gt;&amp;lt;U+5408&amp;gt;                      003
&lt;/pre&gt;
&lt;p&gt;
which looks terrible but does not actually indicate a problem. The information is encoded correctly, but due to a long-standing bug it is &lt;span class="underline"&gt;displayed&lt;/span&gt; incorrectly. You can check to see if the values are correct by converting the data.frame by (ab)using &lt;code&gt;print.listof&lt;/code&gt;, e.g.,
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kp"&gt;print.listof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;read_csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_shiftjis.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		      locale &lt;span class="o"&gt;=&lt;/span&gt; locale&lt;span class="p"&gt;(&lt;/span&gt;encoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"SHIFT-JIS"&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
No. :
[1] "00001" "00002" "00003"

発行日 :
[1] "2015年09月25日" "2015年09月25日" "2015年09月21日"

朝夕刊 :
[1] "週刊" "週刊" "朝刊"

面名 :
[1] "週刊朝日" "週刊朝日" "３総合"  

ページ :
[1] "022" "018" "003"
&lt;/pre&gt;

&lt;p&gt;
To recap: 
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Regardless of platform (Windows, Mac Linux), use the &lt;a href="https://github.com/hadley/readr"&gt;readr&lt;/a&gt; package to read data into R. This will re-encode the contents of the file to UTF-8 for you. 
&lt;/li&gt;
&lt;li&gt;Make sure you specify the encoding using the &lt;code&gt;locale&lt;/code&gt; argument as shown in the example above. 
&lt;/li&gt;
&lt;li&gt;Ignore the ugly &lt;code&gt;print.data.frame&lt;/code&gt; bug and use &lt;code&gt;print.listof&lt;/code&gt; to check that your data was imported correctly.
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
Those wishing for more details about this issue can read on.
&lt;/p&gt;


&lt;div id="outline-container-sec-1" class="outline-2"&gt;
&lt;h2 id="sec-1"&gt;What is the problem?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-1"&gt;
&lt;p&gt;
The problem is that the basic R functions for reading and writing data from and to files does no work in any reasonable way on Windows. If you are struggling with this you are not alone! There are numerous &lt;a href="http://stackoverflow.com/search?tab=votes&amp;amp;q=%255br%255d%2520%255bencoding%255d%2520windows"&gt;questions on stackoverflow&lt;/a&gt;, blog posts (e.g., &lt;a href="http://www.r-bloggers.com/r-and-foreign-characters/"&gt;this one&lt;/a&gt; by Rolf Fredheim, and &lt;a href="http://withr.me/configure-character-encoding-for-r-under-linux-and-windows/"&gt;another&lt;/a&gt; by Huidong Tian), and anguished &lt;a href="http://search.gmane.org/?query=encoding+windows+%2522utf-8%2522+%2522read%2522&amp;amp;author=&amp;amp;group=gmane.comp.lang.r.general&amp;amp;sort=date&amp;amp;DEFAULTOP=and&amp;amp;xP=Zencod%2509Zwindow%2509utf%25098%2509read&amp;amp;xFILTERS=Gcomp.lang.r.general---A"&gt;mailing list posts&lt;/a&gt;. Thinking of the person-hours wasted on this issue over the years almost brings a tear to my eye. 
&lt;/p&gt;

&lt;p&gt;
Let's try it, using some simplified data from a project I worked on last year. For illustration I've created two files containing a mix of English letters, numbers, and Japanese characters. I saved one version with UTF-8 encoding, and another with SHIFT-JIS. On Linux we can read both files easily, provided only that we correctly specify the encoding if the file is not already encoded in UTF-8:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_utf8.csv"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
  No.         発行日 朝夕刊     面名 ページ
1   1 2015年09月25日   週刊 週刊朝日     22
2   2 2015年09月25日   週刊 週刊朝日     18
3   3 2015年09月21日   朝刊   ３総合      3
&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_shiftjis.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; fileEncoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"SHIFT-JIS"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
  No.         発行日 朝夕刊     面名 ページ
1   1 2015年09月25日   週刊 週刊朝日     22
2   2 2015年09月25日   週刊 週刊朝日     18
3   3 2015年09月21日   朝刊   ３総合      3
&lt;/pre&gt;

&lt;p&gt;
On Windows things are much more difficult. Using &lt;code&gt;read.csv&lt;/code&gt; with the default options does not work because &lt;code&gt;read.csv&lt;/code&gt; assumes that the encoding of the file matches the Windows locale settings:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_utf8.csv"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
  No.         ç.ºè.Œæ.. æœ.å..å.Š       é..å.. ãƒšãƒ.ã..
1   1 2015å¹´09æœˆ25æ—¥    é€±åˆŠ é€±åˆŠæœæ—¥        22
2   2 2015å¹´09æœˆ25æ—¥    é€±åˆŠ é€±åˆŠæœæ—¥        18
3   3 2015å¹´09æœˆ21æ—¥    æœåˆŠ    ï¼“ç·åˆ         3
&lt;/pre&gt;

&lt;p&gt;
Trying to tell R that the file is encoded in UTF-8 not a general solution because &lt;code&gt;read.csv&lt;/code&gt; will then try to re-encode from UTF-8 to the native encoding, which may or may not work depending on the contents of the file. On my system trying to read a UTF-8 encoded file containing Japanese characters with the fileEncoding falls flat on its face:
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_utf8.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; fileEncoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"UTF-8"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[1] No. X  
&amp;lt;0 rows&amp;gt; (or 0-length row.names)
Warning messages:
1: In read.table(file = file, header = header, sep = sep, quote = quote,  :
  invalid input found on input connection 'japanese_utf8.csv'
2: In read.table(file = file, header = header, sep = sep, quote = quote,  :
  incomplete final line found by readTableHeader on 'japanese_utf8.csv'
&lt;/pre&gt;


&lt;p&gt;
Finally, we might try the &lt;code&gt;encoding&lt;/code&gt; argument rather than &lt;code&gt;fileEncoding&lt;/code&gt;. This simply marks the strings with the specified encoding:
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_utf8.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; encoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"UTF-8"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
read.csv("japanese_utf8.csv", encoding = "UTF-8")
  No.        X.U.767A..U.884C..U.65E5. X.U.671D..U.5915..U.520A.                X.U.9762..U.540D. X.U.30DA..U.30FC..U.30B8.
1   1 2015&amp;lt;U+5E74&amp;gt;09&amp;lt;U+6708&amp;gt;25&amp;lt;U+65E5&amp;gt;          &amp;lt;U+9031&amp;gt;&amp;lt;U+520A&amp;gt; &amp;lt;U+9031&amp;gt;&amp;lt;U+520A&amp;gt;&amp;lt;U+671D&amp;gt;&amp;lt;U+65E5&amp;gt;                        22
2   2 2015&amp;lt;U+5E74&amp;gt;09&amp;lt;U+6708&amp;gt;25&amp;lt;U+65E5&amp;gt;          &amp;lt;U+9031&amp;gt;&amp;lt;U+520A&amp;gt; &amp;lt;U+9031&amp;gt;&amp;lt;U+520A&amp;gt;&amp;lt;U+671D&amp;gt;&amp;lt;U+65E5&amp;gt;                        18
3   3 2015&amp;lt;U+5E74&amp;gt;09&amp;lt;U+6708&amp;gt;21&amp;lt;U+65E5&amp;gt;          &amp;lt;U+671D&amp;gt;&amp;lt;U+520A&amp;gt;                3&amp;lt;U+7DCF&amp;gt;&amp;lt;U+5408&amp;gt;                         3
&lt;/pre&gt;
&lt;p&gt;
This kind of works, though you wouldn't know it from the output. As mentioned above, there is a bug in the &lt;code&gt;print.data.frame&lt;/code&gt; function that prevents UTF-8 encoded text from displaying correctly. We can use another print method to see that the column values have been read in correctly:
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kp"&gt;print.listof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_utf8.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; encoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"UTF-8"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
No. :
[1] 1 2 3

X.U.767A..U.884C..U.65E5. :
[1] "2015年09月25日" "2015年09月25日" "2015年09月21日"

X.U.671D..U.5915..U.520A. :
[1] "週刊" "週刊" "朝刊"

X.U.9762..U.540D. :
[1] "週刊朝日" "週刊朝日" "３総合"  

X.U.30DA..U.30FC..U.30B8. :
[1] 22 18  3
&lt;/pre&gt;

&lt;p&gt;
Unfortunately there are two problems with this: first, the names of the columns have not been correctly encoded, and second, this will only work if your input data is in UTF-8 in the first place. Trying to apply this strategy to our SHIFT-JIS encoded file will not work at all because we &lt;span class="underline"&gt;cannot&lt;/span&gt; mark strings with arbitrary encoding, only with UTF-8&lt;sup&gt;&lt;a id="fnr.1" name="fnr.1" class="footref" href="http://people.fas.harvard.edu/~izahn/posts/reading-data-with-non-native-encoding-in-r/#fn.1"&gt;1&lt;/a&gt;&lt;/sup&gt;. Trying to mark the string as SHIFT-JIS will silently fail:
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kp"&gt;print.listof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_shiftjis.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; encoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"SHIFT-JIS"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
No. :
[1] 1 2 3

X...s.ú :
[1] "2015”N09ŒŽ25“ú" "2015”N09ŒŽ25“ú" "2015”N09ŒŽ21“ú"

X....Š. :
[1] "TŠ§" "TŠ§" "’©Š§"

X.Ê.. :
[1] "TŠ§’©“ú" "TŠ§’©“ú" "‚R‘‡"  

ƒy..ƒW :
[1] 22 18  3
&lt;/pre&gt;

&lt;p&gt;
Ouch! Why is this so hard? Can we make it suck less?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-2" class="outline-2"&gt;
&lt;h2 id="sec-2"&gt;Encoding in R&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-2"&gt;
&lt;p&gt;
Basically R gives you two ways of handling character encoding. You can use the default encoding of your OS, or you can use UTF-8&lt;sup&gt;&lt;a id="fnr.1.100" name="fnr.1.100" class="footref" href="http://people.fas.harvard.edu/~izahn/posts/reading-data-with-non-native-encoding-in-r/#fn.1"&gt;1&lt;/a&gt;&lt;/sup&gt;. On OS X and Linux these options are often the same, since the default OS encoding is usually UTF-8; this is a great advantage because just about everything can be represented in UTF-8. On Windows there is no such luck. On my Windows 7 machine the default is "Windows code page 1252"; many characters (such as Japanese) cannot be represented in code page 1252. If I want to work with Japanese text in R on Windows I have two options; change my locale to Japanese, or I can convert strings to UTF-8 and mark them as such.
&lt;/p&gt;

&lt;p&gt;
In some ways just changing your locale to one that can accommodate the data you are working with is the simplest approach. Again, on Mac and Linux the locale usually specifies UTF-8 encoding, so no changes are needed; things should just work as you would expect them to. On windows we can change the locale to match the data we are working with using the &lt;code&gt;Sys.setlocale&lt;/code&gt; function. This sometimes works well; for example, we can read our UTF-8 and SHIFT-JIS encoded data on Windows as follows:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;setlocale&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"LC_ALL"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;"English_United States.932"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_shiftjis.csv"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_utf8.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; fileEncoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"UTF-8"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[1] "LC_COLLATE=English_United States.932;LC_CTYPE=English_United States.932;LC_MONETARY=English_United States.932;LC_NUMERIC=C;LC_TIME=English_United States.932"

  No.         発行日 朝夕刊     面名 ページ
1   1 2015年09月25日   週刊 週刊朝日     22
2   2 2015年09月25日   週刊 週刊朝日     18
3   3 2015年09月21日   朝刊   ３総合      3

  No.         発行日 朝夕刊     面名 ページ
1   1 2015年09月25日   週刊 週刊朝日     22
2   2 2015年09月25日   週刊 週刊朝日     18
3   3 2015年09月21日   朝刊   ３総合      3
&lt;/pre&gt;

&lt;p&gt;
This works fine until we want to read some other kind of text in the same R session, and then we are right back to the same old problem. Another issue with this method is that it does not work in Rstudio unless the locale is set on startup; you cannot change the locale of a running session in Rstudio&lt;sup&gt;&lt;a id="fnr.2" name="fnr.2" class="footref" href="http://people.fas.harvard.edu/~izahn/posts/reading-data-with-non-native-encoding-in-r/#fn.2"&gt;2&lt;/a&gt;&lt;/sup&gt;.
&lt;/p&gt;

&lt;p&gt;
Because the &lt;code&gt;Sys.setlocale&lt;/code&gt; method only works for a subset of languages in any given session, our best bet is to read store everything in UTF-8 (and make sure it is marked as such). It is not convenient to do this using the &lt;code&gt;read.table&lt;/code&gt; family of functions in R, but it is possible with some care:
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_shiftjis.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
	      encoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"UTF-8"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
	      check.names &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt; &lt;span class="c1"&gt;# otherwise R will mangle the names&lt;/span&gt;
	      &lt;span class="p"&gt;)&lt;/span&gt;
charcols &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="kp"&gt;sapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;is.numeric&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
x&lt;span class="p"&gt;[&lt;/span&gt;charcols&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;lapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;[&lt;/span&gt;charcols&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="kp"&gt;iconv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; from &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"SHIFT-JIS"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; to &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"UTF-8"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kp"&gt;names&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;iconv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;names&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;),&lt;/span&gt; from &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"SHIFT-JIS"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; to &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"UTF-8"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kp"&gt;print.listof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
No. :
[1] 1 2 3

発行日 :
[1] "2015年09月25日" "2015年09月25日" "2015年09月21日"

朝夕刊 :
[1] "週刊" "週刊" "朝刊"

面名 :
[1] "週刊朝日" "週刊朝日" "３総合"  

ページ :
[1] 22 18  3
&lt;/pre&gt;
&lt;p&gt;
OK it works, but honestly that too much work for something as simple as reading a .csv file into R. As suggested at the beginning of this post, a better strategy is to use the &lt;a href="https://github.com/hadley/readr"&gt;readr&lt;/a&gt; package because it will do the conversion to UTF-8 for you:
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kp"&gt;print.listof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;read_csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"arabic_utf-8.csv"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; locale &lt;span class="o"&gt;=&lt;/span&gt; locale&lt;span class="p"&gt;(&lt;/span&gt;encoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"UTF-8"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="kp"&gt;print.listof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;read_csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_utf8.csv"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; locale &lt;span class="o"&gt;=&lt;/span&gt; locale&lt;span class="p"&gt;(&lt;/span&gt;encoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"UTF-8"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="kp"&gt;print.listof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;read_csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"japanese_shiftjis.csv"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; locale &lt;span class="o"&gt;=&lt;/span&gt; locale&lt;span class="p"&gt;(&lt;/span&gt;encoding &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"SHIFT-JIS"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
X5 :
[1] "1895-01-02" "1895-01-07" "1895-01-16"
X8 :
[1] "اصلى" "اصلى" "اصلى"
X12 :
[1] "وقائع" "وقائع" "وقائع"

No. :
[1] "00001" "00002" "00003"
発行日 :
[1] "2015年09月25日" "2015年09月25日" "2015年09月21日"
朝夕刊 :
[1] "週刊" "週刊" "朝刊"
面名 :
[1] "週刊朝日" "週刊朝日" "３総合"  
ページ :
[1] "022" "018" "003"


No. :
[1] "00001" "00002" "00003"
発行日 :
[1] "2015年09月25日" "2015年09月25日" "2015年09月21日"
朝夕刊 :
[1] "週刊" "週刊" "朝刊"
面名 :
[1] "週刊朝日" "週刊朝日" "３総合"  
ページ :
[1] "022" "018" "003"
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-sec-3" class="outline-2"&gt;
&lt;h2 id="sec-3"&gt;Files&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-3"&gt;
&lt;p&gt;
Here are the &lt;a href="http://people.fas.harvard.edu/~izahn/example_files/blog/encoding_hell.zip"&gt;example data files and code&lt;/a&gt; and needed to run the examples in this post.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="footnotes"&gt;
&lt;h2 class="footnotes"&gt;Footnotes: &lt;/h2&gt;
&lt;div id="text-footnotes"&gt;

&lt;div class="footdef"&gt;&lt;sup&gt;&lt;a id="fn.1" name="fn.1" class="footnum" href="http://people.fas.harvard.edu/~izahn/posts/reading-data-with-non-native-encoding-in-r/#fnr.1"&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;p class="footpara"&gt;
We can also mark strings as encoded in &lt;code&gt;latin1&lt;/code&gt;, but that is not useful if you take my advice and store everything in UTF-8.
&lt;/p&gt;&lt;/div&gt;

&lt;div class="footdef"&gt;&lt;sup&gt;&lt;a id="fn.2" name="fn.2" class="footnum" href="http://people.fas.harvard.edu/~izahn/posts/reading-data-with-non-native-encoding-in-r/#fnr.2"&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;p class="footpara"&gt;
See &lt;a href="https://support.rstudio.com/hc/en-us/articles/200532197-Character-Encoding"&gt;https://support.rstudio.com/hc/en-us/articles/200532197-Character-Encoding&lt;/a&gt;
&lt;/p&gt;&lt;/div&gt;


&lt;/div&gt;
&lt;/div&gt;</description><category>Encoding</category><category>Files</category><category>R</category><category>SHIFT-JIS</category><category>UTF-8</category><guid>http://people.fas.harvard.edu/~izahn/posts/reading-data-with-non-native-encoding-in-r/</guid><pubDate>Tue, 14 Jun 2016 17:57:09 GMT</pubDate></item></channel></rss>